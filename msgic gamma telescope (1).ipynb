{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560682cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikeras) (20.9)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikeras) (1.1.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.20.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146897c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03af3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c338671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91b73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972e07e",
   "metadata": {},
   "source": [
    "## Read dataset into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6635d0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flength</th>\n",
       "      <th>fwidth</th>\n",
       "      <th>fsize</th>\n",
       "      <th>fconc</th>\n",
       "      <th>fconc1</th>\n",
       "      <th>fsym</th>\n",
       "      <th>fm3long</th>\n",
       "      <th>fm3trans</th>\n",
       "      <th>falpha</th>\n",
       "      <th>dist</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    flength    fwidth   fsize   fconc  fconc1      fsym  fm3long  fm3trans  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
       "\n",
       "    falpha      dist class  \n",
       "0  40.0920   81.8828     g  \n",
       "1   6.3609  205.2610     g  \n",
       "2  76.9600  256.7880     g  \n",
       "3  10.4490  116.7370     g  \n",
       "4   4.6480  356.4620     g  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('magic_gamma_telescope04_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd58b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    2183\n",
       "h    2104\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facda3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flength</th>\n",
       "      <th>fwidth</th>\n",
       "      <th>fsize</th>\n",
       "      <th>fconc</th>\n",
       "      <th>fconc1</th>\n",
       "      <th>fsym</th>\n",
       "      <th>fm3long</th>\n",
       "      <th>fm3trans</th>\n",
       "      <th>falpha</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "      <td>4287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.716420</td>\n",
       "      <td>24.135054</td>\n",
       "      <td>2.849275</td>\n",
       "      <td>0.375352</td>\n",
       "      <td>0.212399</td>\n",
       "      <td>-8.742164</td>\n",
       "      <td>7.314128</td>\n",
       "      <td>0.642312</td>\n",
       "      <td>31.757071</td>\n",
       "      <td>195.702966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.897591</td>\n",
       "      <td>21.823325</td>\n",
       "      <td>0.472802</td>\n",
       "      <td>0.181586</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>66.928938</td>\n",
       "      <td>56.577545</td>\n",
       "      <td>24.176600</td>\n",
       "      <td>27.188376</td>\n",
       "      <td>76.210147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.360600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.991600</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-382.594000</td>\n",
       "      <td>-318.300200</td>\n",
       "      <td>-205.894700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.587650</td>\n",
       "      <td>11.904000</td>\n",
       "      <td>2.501100</td>\n",
       "      <td>0.232650</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>-25.685900</td>\n",
       "      <td>-15.003250</td>\n",
       "      <td>-10.895600</td>\n",
       "      <td>7.439800</td>\n",
       "      <td>142.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.875400</td>\n",
       "      <td>17.389500</td>\n",
       "      <td>2.757400</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>1.845800</td>\n",
       "      <td>14.907700</td>\n",
       "      <td>1.910700</td>\n",
       "      <td>23.821000</td>\n",
       "      <td>193.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>75.201750</td>\n",
       "      <td>26.154050</td>\n",
       "      <td>3.131400</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>23.421500</td>\n",
       "      <td>34.763650</td>\n",
       "      <td>11.382700</td>\n",
       "      <td>53.004700</td>\n",
       "      <td>242.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.177000</td>\n",
       "      <td>256.382000</td>\n",
       "      <td>5.323300</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.628300</td>\n",
       "      <td>575.240700</td>\n",
       "      <td>238.321000</td>\n",
       "      <td>179.851000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>450.953000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           flength       fwidth        fsize        fconc       fconc1  \\\n",
       "count  4287.000000  4287.000000  4287.000000  4287.000000  4287.000000   \n",
       "mean     57.716420    24.135054     2.849275     0.375352     0.212399   \n",
       "std      47.897591    21.823325     0.472802     0.181586     0.110284   \n",
       "min       7.360600     0.000000     1.991600     0.013100     0.000300   \n",
       "25%      24.587650    11.904000     2.501100     0.232650     0.126450   \n",
       "50%      38.875400    17.389500     2.757400     0.352600     0.196000   \n",
       "75%      75.201750    26.154050     3.131400     0.503000     0.285400   \n",
       "max     334.177000   256.382000     5.323300     0.893000     0.628300   \n",
       "\n",
       "              fsym      fm3long     fm3trans       falpha         dist  \n",
       "count  4287.000000  4287.000000  4287.000000  4287.000000  4287.000000  \n",
       "mean     -8.742164     7.314128     0.642312    31.757071   195.702966  \n",
       "std      66.928938    56.577545    24.176600    27.188376    76.210147  \n",
       "min    -382.594000  -318.300200  -205.894700     0.000000     5.745600  \n",
       "25%     -25.685900   -15.003250   -10.895600     7.439800   142.827500  \n",
       "50%       1.845800    14.907700     1.910700    23.821000   193.740000  \n",
       "75%      23.421500    34.763650    11.382700    53.004700   242.893700  \n",
       "max     575.240700   238.321000   179.851000    90.000000   450.953000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4ee927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4287 entries, 0 to 4286\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   flength   4287 non-null   float64\n",
      " 1   fwidth    4287 non-null   float64\n",
      " 2   fsize     4287 non-null   float64\n",
      " 3   fconc     4287 non-null   float64\n",
      " 4   fconc1    4287 non-null   float64\n",
      " 5   fsym      4287 non-null   float64\n",
      " 6   fm3long   4287 non-null   float64\n",
      " 7   fm3trans  4287 non-null   float64\n",
      " 8   falpha    4287 non-null   float64\n",
      " 9   dist      4287 non-null   float64\n",
      " 10  class     4287 non-null   object \n",
      "dtypes: float64(10), object(1)\n",
      "memory usage: 368.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51150d7d",
   "metadata": {},
   "source": [
    "No null values or type problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca8bac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1).values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762a7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf12c57",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4007052",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43d1b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fit = scale.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf3f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_fit.transform(X_train)\n",
    "X_test = train_fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d9251",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4915ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_en = le.fit_transform(y)\n",
    "y_train_en = le.fit_transform(y_train)\n",
    "y_test_en = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9516cf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3429, 10), (858, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c945623",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bcea4",
   "metadata": {},
   "source": [
    "Building an initial ANN model randomly to assess performance. Using two hidden layers with 16 neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b511169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_shape=(10,), activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366a97e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09088b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "286/286 [==============================] - 5s 9ms/step - loss: 0.6379 - accuracy: 0.6582 - val_loss: 0.5709 - val_accuracy: 0.7646\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.7626 - val_loss: 0.4983 - val_accuracy: 0.7692\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.7737 - val_loss: 0.4801 - val_accuracy: 0.7844\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.7842 - val_loss: 0.4743 - val_accuracy: 0.7844\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4561 - accuracy: 0.7792 - val_loss: 0.4695 - val_accuracy: 0.7809\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4483 - accuracy: 0.7819 - val_loss: 0.4509 - val_accuracy: 0.7937\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4417 - accuracy: 0.7877 - val_loss: 0.4450 - val_accuracy: 0.7949\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4358 - accuracy: 0.7938 - val_loss: 0.4446 - val_accuracy: 0.7937\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4332 - accuracy: 0.7912 - val_loss: 0.4408 - val_accuracy: 0.7984\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4305 - accuracy: 0.7927 - val_loss: 0.4293 - val_accuracy: 0.7937\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4252 - accuracy: 0.8005 - val_loss: 0.4392 - val_accuracy: 0.7925\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4214 - accuracy: 0.8034 - val_loss: 0.4263 - val_accuracy: 0.8019\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4190 - accuracy: 0.8049 - val_loss: 0.4305 - val_accuracy: 0.8007\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8110 - val_loss: 0.4334 - val_accuracy: 0.7925\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8116 - val_loss: 0.4251 - val_accuracy: 0.7925\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4148 - accuracy: 0.8014 - val_loss: 0.4175 - val_accuracy: 0.7984\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4147 - accuracy: 0.8101 - val_loss: 0.4202 - val_accuracy: 0.8042\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4115 - accuracy: 0.8119 - val_loss: 0.4203 - val_accuracy: 0.8007\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4114 - accuracy: 0.8148 - val_loss: 0.4185 - val_accuracy: 0.8077\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4091 - accuracy: 0.8128 - val_loss: 0.4162 - val_accuracy: 0.8019\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4080 - accuracy: 0.8128 - val_loss: 0.4148 - val_accuracy: 0.7984\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4087 - accuracy: 0.8104 - val_loss: 0.4260 - val_accuracy: 0.7914\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4067 - accuracy: 0.8148 - val_loss: 0.4199 - val_accuracy: 0.7984\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4034 - accuracy: 0.8215 - val_loss: 0.4164 - val_accuracy: 0.8019\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4018 - accuracy: 0.8157 - val_loss: 0.4104 - val_accuracy: 0.8089\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.4048 - accuracy: 0.8198 - val_loss: 0.4117 - val_accuracy: 0.8089\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4036 - accuracy: 0.8160 - val_loss: 0.4119 - val_accuracy: 0.8030\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4006 - accuracy: 0.8215 - val_loss: 0.4152 - val_accuracy: 0.8089\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.4005 - accuracy: 0.8209 - val_loss: 0.4072 - val_accuracy: 0.8124\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.4000 - accuracy: 0.8239 - val_loss: 0.4184 - val_accuracy: 0.8042\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.3998 - accuracy: 0.8212 - val_loss: 0.4109 - val_accuracy: 0.8124\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.3988 - accuracy: 0.8206 - val_loss: 0.4128 - val_accuracy: 0.8054\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 2s 5ms/step - loss: 0.3998 - accuracy: 0.8250 - val_loss: 0.4122 - val_accuracy: 0.8019\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.3984 - accuracy: 0.8221 - val_loss: 0.4195 - val_accuracy: 0.7902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6ef00a8e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_en, batch_size=12, epochs=100, \n",
    "          validation_data=(X_test, y_test_en), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b0a328b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.637866</td>\n",
       "      <td>0.658209</td>\n",
       "      <td>0.570947</td>\n",
       "      <td>0.764569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.530764</td>\n",
       "      <td>0.762613</td>\n",
       "      <td>0.498332</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487789</td>\n",
       "      <td>0.773695</td>\n",
       "      <td>0.480139</td>\n",
       "      <td>0.784382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469458</td>\n",
       "      <td>0.784194</td>\n",
       "      <td>0.474297</td>\n",
       "      <td>0.784382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456132</td>\n",
       "      <td>0.779236</td>\n",
       "      <td>0.469494</td>\n",
       "      <td>0.780886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.448308</td>\n",
       "      <td>0.781861</td>\n",
       "      <td>0.450888</td>\n",
       "      <td>0.793706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.441718</td>\n",
       "      <td>0.787693</td>\n",
       "      <td>0.444974</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.435758</td>\n",
       "      <td>0.793817</td>\n",
       "      <td>0.444631</td>\n",
       "      <td>0.793706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.433161</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.440832</td>\n",
       "      <td>0.798368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.430510</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.429265</td>\n",
       "      <td>0.793706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.425176</td>\n",
       "      <td>0.800525</td>\n",
       "      <td>0.439234</td>\n",
       "      <td>0.792541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.421401</td>\n",
       "      <td>0.803441</td>\n",
       "      <td>0.426323</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.418988</td>\n",
       "      <td>0.804899</td>\n",
       "      <td>0.430531</td>\n",
       "      <td>0.800699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.418029</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.433384</td>\n",
       "      <td>0.792541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.416044</td>\n",
       "      <td>0.811607</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.792541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.414807</td>\n",
       "      <td>0.801400</td>\n",
       "      <td>0.417519</td>\n",
       "      <td>0.798368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.414669</td>\n",
       "      <td>0.810149</td>\n",
       "      <td>0.420178</td>\n",
       "      <td>0.804196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.411461</td>\n",
       "      <td>0.811899</td>\n",
       "      <td>0.420283</td>\n",
       "      <td>0.800699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.418517</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.409137</td>\n",
       "      <td>0.812773</td>\n",
       "      <td>0.416193</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.407960</td>\n",
       "      <td>0.812773</td>\n",
       "      <td>0.414791</td>\n",
       "      <td>0.798368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.408709</td>\n",
       "      <td>0.810440</td>\n",
       "      <td>0.425981</td>\n",
       "      <td>0.791375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.406652</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.419863</td>\n",
       "      <td>0.798368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.403396</td>\n",
       "      <td>0.821522</td>\n",
       "      <td>0.416444</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.401751</td>\n",
       "      <td>0.815690</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.808858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.404761</td>\n",
       "      <td>0.819773</td>\n",
       "      <td>0.411679</td>\n",
       "      <td>0.808858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.403627</td>\n",
       "      <td>0.815981</td>\n",
       "      <td>0.411887</td>\n",
       "      <td>0.803030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.400620</td>\n",
       "      <td>0.821522</td>\n",
       "      <td>0.415164</td>\n",
       "      <td>0.808858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.400491</td>\n",
       "      <td>0.820939</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>0.812354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.399982</td>\n",
       "      <td>0.823855</td>\n",
       "      <td>0.418436</td>\n",
       "      <td>0.804196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.399813</td>\n",
       "      <td>0.821231</td>\n",
       "      <td>0.410877</td>\n",
       "      <td>0.812354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.398831</td>\n",
       "      <td>0.820647</td>\n",
       "      <td>0.412819</td>\n",
       "      <td>0.805361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.399751</td>\n",
       "      <td>0.825022</td>\n",
       "      <td>0.412201</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.398386</td>\n",
       "      <td>0.822106</td>\n",
       "      <td>0.419518</td>\n",
       "      <td>0.790210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.637866  0.658209  0.570947      0.764569\n",
       "1   0.530764  0.762613  0.498332      0.769231\n",
       "2   0.487789  0.773695  0.480139      0.784382\n",
       "3   0.469458  0.784194  0.474297      0.784382\n",
       "4   0.456132  0.779236  0.469494      0.780886\n",
       "5   0.448308  0.781861  0.450888      0.793706\n",
       "6   0.441718  0.787693  0.444974      0.794872\n",
       "7   0.435758  0.793817  0.444631      0.793706\n",
       "8   0.433161  0.791193  0.440832      0.798368\n",
       "9   0.430510  0.792651  0.429265      0.793706\n",
       "10  0.425176  0.800525  0.439234      0.792541\n",
       "11  0.421401  0.803441  0.426323      0.801865\n",
       "12  0.418988  0.804899  0.430531      0.800699\n",
       "13  0.418029  0.811024  0.433384      0.792541\n",
       "14  0.416044  0.811607  0.425100      0.792541\n",
       "15  0.414807  0.801400  0.417519      0.798368\n",
       "16  0.414669  0.810149  0.420178      0.804196\n",
       "17  0.411461  0.811899  0.420283      0.800699\n",
       "18  0.411400  0.814815  0.418517      0.807692\n",
       "19  0.409137  0.812773  0.416193      0.801865\n",
       "20  0.407960  0.812773  0.414791      0.798368\n",
       "21  0.408709  0.810440  0.425981      0.791375\n",
       "22  0.406652  0.814815  0.419863      0.798368\n",
       "23  0.403396  0.821522  0.416444      0.801865\n",
       "24  0.401751  0.815690  0.410448      0.808858\n",
       "25  0.404761  0.819773  0.411679      0.808858\n",
       "26  0.403627  0.815981  0.411887      0.803030\n",
       "27  0.400620  0.821522  0.415164      0.808858\n",
       "28  0.400491  0.820939  0.407228      0.812354\n",
       "29  0.399982  0.823855  0.418436      0.804196\n",
       "30  0.399813  0.821231  0.410877      0.812354\n",
       "31  0.398831  0.820647  0.412819      0.805361\n",
       "32  0.399751  0.825022  0.412201      0.801865\n",
       "33  0.398386  0.822106  0.419518      0.790210"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_metrics = pd.DataFrame(model.history.history)\n",
    "ann_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c6b77",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eadff1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ec962",
   "metadata": {},
   "source": [
    "The model has reached limit and would over fit on further epochs. Validation and train loss moving down togther is good indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82fca3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(X_test) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca36c67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.80       461\n",
      "           1       0.76      0.81      0.78       397\n",
      "\n",
      "    accuracy                           0.79       858\n",
      "   macro avg       0.79      0.79      0.79       858\n",
      "weighted avg       0.79      0.79      0.79       858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_en, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d415bdc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[357, 104],\n",
       "       [ 76, 321]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_en, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b09994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7902097902097902"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_en, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6516e256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781021897810219"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_en, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7fc3b3",
   "metadata": {},
   "source": [
    "just an initial model gave 79.02% accuracy and 78.10% f-1 score. Initial objectives completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ef18d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c53922",
   "metadata": {},
   "source": [
    "Used grid search with a sklearn wrapper of keras called scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6061a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons, dropout_rate, optimizer='adam'):\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(neurons, input_shape=(10,), activation='relu'))\n",
    "\tmodel.add(Dropout(dropout_rate))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e96845",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adam']\n",
    "dropout_rate = [0.2, 0.3, 0.4, 0.5]\n",
    "neurons = [15, 20, 25, 30]\n",
    "\n",
    "param_grid = dict(model__optimizer=optimizer, model__dropout_rate=dropout_rate, \n",
    "                  model__neurons=neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b899faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349356db",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb10ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c34a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
